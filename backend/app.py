import os 
import sys
import asyncio
import requests
import time
from bs4 import BeautifulSoup
import json
from typing import List, Dict, Any, Generator
from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from langchain_tavily import TavilySearch
from tavily import TavilyClient
from langchain.agents import initialize_agent, Tool
from langchain_core.tools import tool
from langchain.schema import HumanMessage
from langgraph.prebuilt import create_react_agent
from langchain_community.chat_models.tongyi import ChatTongyi
from langgraph.checkpoint.memory import MemorySaver





# åˆå§‹åŒ–æ¨¡å‹
llm = ChatTongyi(api_key="sk-f434639a7e1345ed99c660461d92389d", model_name="qwen-max")
tavily_client = TavilyClient(api_key="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")

@tool
def read_doc_file(file_path: str):
    """è¯»å–ç”¨æˆ·å½“å‰è§‚çœ‹æ–‡æ¡£çš„å®Œæ•´è·¯å¾„ã€‚"""
    import os
    import urllib.parse
    
    # URL è§£ç 
    try:
        decoded_path = urllib.parse.unquote(file_path)
    except Exception as e:
        print(f"URLè§£ç å¤±è´¥: {e}")
        decoded_path = file_path
    
    # å»é™¤é¦–å°¾ç©ºæ ¼
    decoded_path = decoded_path.strip()
    
    # å¤„ç†ä¸åŒçš„è·¯å¾„æ ¼å¼ï¼Œæå–å®é™…æ–‡æ¡£è·¯å¾„
    if decoded_path.startswith('/docs/'):
        doc_path = decoded_path[6:]  # å»æ‰ '/docs/'
    elif decoded_path.startswith('docs/'):
        doc_path = decoded_path[5:]  # å»æ‰ 'docs/'
    else:
        doc_path = decoded_path  # ç›´æ¥æ˜¯æ–‡ä»¶å
    
    # å»é™¤å¯èƒ½çš„å°¾éƒ¨æ–œæ 
    doc_path = doc_path.rstrip('/')
    
    # æ„å»ºå®Œæ•´è·¯å¾„
    full_path = "../docs/" + doc_path
    # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œæ·»åŠ  .md
    if not full_path.endswith('.md'):
        full_path += '.md'
    
    print(f"å½“å‰ç”¨æˆ·æµè§ˆçš„æ–‡æ¡£å®Œæ•´è·¯å¾„ï¼š{full_path}")
    
    try:
        with open(full_path, "r") as f:
            content = f.read()
            return f"æ–‡ä»¶å†…å®¹ï¼š\n\n{content}"
    except FileNotFoundError:
        return f"æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{full_path}"
    except Exception as e:
        return f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}"

@tool
def write_file(file_name: str, content: str):
    """åˆ›å»ºæˆ–ä¿®æ”¹Markdownæ–‡ä»¶"""
    import os
    import threading
    import time
    
    try:
        # ç¡®ä¿æ–‡ä»¶åæœ‰.mdæ‰©å±•å
        if not file_name.endswith('.md'):
            file_name += '.md'
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = "../temp_docs"
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir, exist_ok=True)
        
        # å…ˆå†™å…¥ä¸´æ—¶ç›®å½•
        temp_path = os.path.join(temp_dir, file_name)
        
        # ç¡®ä¿ä¸´æ—¶ç›®å½•çš„å­ç›®å½•å­˜åœ¨
        temp_dir_path = os.path.dirname(temp_path)
        if temp_dir_path and temp_dir_path != temp_dir and not os.path.exists(temp_dir_path):
            os.makedirs(temp_dir_path, exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir_path}")
        
        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        with open(temp_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"ğŸ“ æ–‡ä»¶å·²å†™å…¥ä¸´æ—¶ç›®å½•: {temp_path}")
        
        # å®šä¹‰å»¶è¿Ÿç§»åŠ¨å‡½æ•°
        def delayed_move():
            try:
                # ç­‰å¾…8ç§’ï¼Œç¡®ä¿AIå›å¤å®Œæˆ
                time.sleep(8)
                
                # æ„å»ºæœ€ç»ˆè·¯å¾„
                final_path = os.path.join("../docs", file_name)
                final_dir_path = os.path.dirname(final_path)
                
                # ç¡®ä¿æœ€ç»ˆç›®å½•å­˜åœ¨
                if final_dir_path and not os.path.exists(final_dir_path):
                    os.makedirs(final_dir_path, exist_ok=True)
                    print(f"ğŸ“ åˆ›å»ºæœ€ç»ˆç›®å½•: {final_dir_path}")
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°æœ€ç»ˆä½ç½®
                import shutil
                shutil.move(temp_path, final_path)
                print(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®: {final_path}")
                
            except Exception as e:
                print(f"âŒ å»¶è¿Ÿç§»åŠ¨æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        # å¯åŠ¨åå°çº¿ç¨‹è¿›è¡Œå»¶è¿Ÿç§»åŠ¨
        move_thread = threading.Thread(target=delayed_move, daemon=True)
        move_thread.start()
        
        # ç«‹å³è¿”å›æˆåŠŸä¿¡æ¯ï¼ˆæ­¤æ—¶æ–‡ä»¶è¿˜åœ¨ä¸´æ—¶ç›®å½•ï¼‰
        final_path = os.path.join("../docs", file_name)
        temp_file_size = os.path.getsize(temp_path)
        
        return f"âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼\nğŸ“„ æ–‡ä»¶å: {file_name}\nğŸ“ è·¯å¾„: {final_path}\nğŸ“Š å¤§å°: {temp_file_size} å­—èŠ‚\nğŸ’¾ ç¼–ç : UTF-8\n\nğŸ’¡ æç¤ºï¼šæ–‡ä»¶å°†åœ¨å‡ ç§’åå‡ºç°åœ¨æ–‡æ¡£ç›®å½•ä¸­ï¼Œé¿å…æ‰“æ–­å½“å‰å¯¹è¯ã€‚"
        
    except PermissionError:
        return f"âŒ æƒé™é”™è¯¯ï¼šæ— æ³•å†™å…¥æ–‡ä»¶ {file_name}ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™"
    except FileNotFoundError:
        return f"âŒ è·¯å¾„é”™è¯¯ï¼šç›®æ ‡ç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºæ–‡ä»¶ {file_name}"
    except UnicodeEncodeError:
        return f"âŒ ç¼–ç é”™è¯¯ï¼šæ–‡ä»¶å†…å®¹åŒ…å«æ— æ³•ç¼–ç çš„å­—ç¬¦"
    except Exception as e:
        return f"âŒ å†™å…¥æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"


@tool
def extract_webpage_content(url):
    """
    æå–ç½‘é¡µå†…å®¹çš„å·¥å…·å‡½æ•°
    """
    try:
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Connection': 'keep-alive'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(url, headers=headers, allow_redirects=True, timeout=15)
        response.raise_for_status()
        
        # è§£æHTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ç§»é™¤æ— ç”¨æ ‡ç­¾
        for tag in soup(["script", "style", "nav", "footer", "header"]):
            tag.decompose()
        
        # æå–æ–‡æœ¬å†…å®¹
        text_content = soup.get_text()
        lines = (line.strip() for line in text_content.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        content = ' '.join(chunk for chunk in chunks if chunk)
        
        return content
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'url': url
        }


search = TavilySearch(max_results=2)

# åˆå§‹åŒ–å†…å­˜å’Œå·¥å…·
memory = MemorySaver()

# æ›´æ–°æç¤ºè¯ï¼Œå‡å°‘å¯¹é¡µé¢ä¸Šä¸‹æ–‡çš„è¿‡åº¦å…³æ³¨
prompt = """
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·è§£å†³å„ç§é—®é¢˜ã€‚

ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. ğŸ“š è¯»å–å’Œåˆ†ææ–‡æ¡£å†…å®¹ï¼ˆå½“ç”¨æˆ·éœ€è¦æ—¶ï¼‰
2. âœï¸ åˆ›å»ºå’Œä¿®æ”¹æ–‡ä»¶ï¼ˆå½“ç”¨æˆ·éœ€è¦æ—¶ï¼‰
3. ğŸŒ æå–å’Œåˆ†æç½‘é¡µå†…å®¹ï¼ˆå½“ç”¨æˆ·è¯¢é—®æŸä¸ªç½‘å€çš„å†…å®¹æ—¶ï¼‰
4. ğŸ” æœç´¢äº’è”ç½‘ä¿¡æ¯
5. ğŸ’¬ è¿›è¡Œè‡ªç„¶ã€å‹å¥½çš„å¯¹è¯
6. ğŸ’¡ æä¾›æœ‰ç”¨çš„å»ºè®®å’Œä¿¡æ¯

è¯·è‡ªç„¶åœ°ä¸ç”¨æˆ·å¯¹è¯ï¼Œæ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚æ¥å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·ï¼š
- åªæœ‰å½“ç”¨æˆ·æ˜ç¡®è¯¢é—®æ–‡æ¡£å†…å®¹æˆ–éœ€è¦æŸ¥çœ‹ç‰¹å®šæ–‡ä»¶æ—¶ï¼Œæ‰ä½¿ç”¨ read_doc_file å·¥å…·
- åªæœ‰å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚åˆ›å»ºæˆ–ä¿®æ”¹æ–‡ä»¶æ—¶ï¼Œæ‰ä½¿ç”¨ write_file å·¥å…·
- å½“ç”¨æˆ·è¯¢é—®æŸä¸ªå…·ä½“ç½‘å€çš„å†…å®¹æ—¶ï¼Œä½¿ç”¨ extract_webpage_content å·¥å…·
- å½“ç”¨æˆ·éœ€è¦æœç´¢ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ search å·¥å…·
- å¯¹äºä¸€èˆ¬æ€§çš„é—®å€™ã€é—²èŠæˆ–å’¨è¯¢ï¼Œè¯·ç›´æ¥å‹å¥½åœ°å›åº”

ä¿æŒå¯¹è¯è‡ªç„¶æµç•…ï¼Œä¸è¦ä¸»åŠ¨æåŠæŠ€æœ¯ç»†èŠ‚æˆ–é¡µé¢ä¿¡æ¯ï¼Œé™¤éç”¨æˆ·ç‰¹åˆ«è¯¢é—®ã€‚
"""

tools = [read_doc_file, write_file, search, extract_webpage_content]
agent = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)

# å…¨å±€é…ç½®
config = {"configurable": {"thread_id": "unique_thread_id"}}

from typing import List, Dict

class WebsiteAgent:
    """ç½‘ç«™æ™ºèƒ½åŠ©æ‰‹åŒ…è£…ç±»"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–æ™ºèƒ½åŠ©æ‰‹
        
        Args:
            agent: æ™ºèƒ½åŠ©æ‰‹å®ä¾‹
            config: é…ç½®å¯¹è±¡
        """
        self.agent = agent
        self.config = config
    
    async def chat_stream_async(self, messages: List[Dict], page_path: str = None):
        """å¼‚æ­¥æµå¼èŠå¤©æ¥å£"""
        try:
            # æ£€æŸ¥æ¶ˆæ¯åˆ—è¡¨æ˜¯å¦ä¸ºç©º
            if not messages:
                error_msg = "âŒ æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º"
                print(error_msg)
                yield error_msg
                return
            
            # å‡†å¤‡ç”¨æˆ·è¾“å…¥
            user_input = messages[-1]["content"]
            
            if page_path:
                context_info = f"\n\nå½“å‰ç”¨æˆ·æµè§ˆçš„æ–‡æ¡£è·¯å¾„ï¼š{page_path}"
                user_input_with_context = user_input + context_info
            else:
                user_input_with_context = user_input
            
            # è®°å½•è¯·æ±‚ä¿¡æ¯
            print(f"ğŸ¤– Agent å¤„ç†è¯·æ±‚ï¼š{user_input[:50]}...")
            
            if page_path:
                print(f"ğŸ“ æ–‡æ¡£è·¯å¾„ï¼š{page_path}")
    
            input_message = {
                "role": "user",
                "content": user_input_with_context,
            }
    
            print("ğŸ”„ å¼€å§‹æµå¼å¤„ç†...")
            has_output = False
            tool_called = set()  # è®°å½•å·²è°ƒç”¨çš„å·¥å…·ï¼Œé¿å…é‡å¤æç¤º
            
            async for chunk_data in self.agent.astream(
                {"messages": [input_message]}, 
                self.config,
                stream_mode="messages"
            ):
                try:
                    # chunk_data æ˜¯ä¸€ä¸ªå…ƒç»„ï¼š(message, metadata)
                    if isinstance(chunk_data, tuple) and len(chunk_data) == 2:
                        message, metadata = chunk_data
                        print(f"ğŸ“¦ æ”¶åˆ°æ¶ˆæ¯: {type(message).__name__}, å…ƒæ•°æ®: {metadata.get('langgraph_node', 'unknown')}")
                    else:
                        # å¦‚æœä¸æ˜¯å…ƒç»„ï¼Œç›´æ¥å½“ä½œæ¶ˆæ¯å¤„ç†
                        message = chunk_data
                        print(f"ğŸ“¦ æ”¶åˆ°æ¶ˆæ¯: {type(message).__name__}")
                    
                    message_type = type(message).__name__


                    # å¤„ç†AIæ¶ˆæ¯ - åŒ…æ‹¬AIMessageå’ŒAIMessageChunk
                    if message_type in ["AIMessage", "AIMessageChunk"]:
                        if hasattr(message, 'content') and message.content:
                            print(f"ğŸ“¤ AIå›å¤å†…å®¹: {repr(message.content)}")
                            yield message.content
                            has_output = True
                        else:
                            print(f"ğŸ“¤ AIæ¶ˆæ¯æ— å†…å®¹: {message}")
                    
                    # é™é»˜å¤„ç†å·¥å…·è°ƒç”¨ - ä¸è¾“å‡ºä»»ä½•ä¿¡æ¯
                    if hasattr(message, 'tool_calls') and message.tool_calls:
                        for tool_call in message.tool_calls:
                            tool_name = tool_call.get('name', 'æœªçŸ¥å·¥å…·')
                            print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name} (é™é»˜å¤„ç†)")
                    
                    # é™é»˜è·³è¿‡å·¥å…·è°ƒç”¨ç»“æœ
                    if message_type == "ToolMessage":
                        print(f"ğŸ”§ å·¥å…·è°ƒç”¨å®Œæˆ (é™é»˜è·³è¿‡)")
                        continue
                    
                    # é™é»˜è·³è¿‡æ— æ•ˆçš„å·¥å…·è°ƒç”¨ç‰‡æ®µ
                    if hasattr(message, 'invalid_tool_calls') and message.invalid_tool_calls:
                        print("â­ï¸ è·³è¿‡æ— æ•ˆå·¥å…·è°ƒç”¨ç‰‡æ®µ (é™é»˜)")
                        continue
                    
                except Exception as chunk_error:
                    # å¤„ç†å•ä¸ªchunkçš„é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                    print(f"âš ï¸ å¤„ç†chunkæ—¶å‡ºé”™: {chunk_error}")
                    continue
            
            print("âœ… æµå¼å¤„ç†å®Œæˆ")
            
            # å¦‚æœæ²¡æœ‰è¾“å‡ºï¼Œæä¾›é»˜è®¤å“åº”
            if not has_output:
                print("âš ï¸ æ²¡æœ‰æ”¶åˆ°ä»»ä½•æœ‰æ•ˆè¾“å‡ºï¼Œæä¾›é»˜è®¤å“åº”")
                default_response = "ä½ å¥½ï¼æˆ‘æ”¶åˆ°äº†ä½ çš„æ¶ˆæ¯ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
                yield default_response
                
        except Exception as e:
            error_msg = f"âŒ Agent æ‰§è¡Œé”™è¯¯ï¼š{str(e)}"
            print(error_msg)
            import traceback
            print(f"ğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š{traceback.format_exc()}")
            yield error_msg

    
    def chat_stream(self, messages: List[Dict], page_path: str = None) -> Generator[str, None, None]:
        """åŒæ­¥åŒ…è£…å™¨"""
        print(f"ğŸ”„ chat_stream æ¥æ”¶åˆ°å‚æ•°:")
        print(f"  - messagesæ•°é‡: {len(messages)}")
        print(f"  - page_path: {repr(page_path)}")
        
        import asyncio
        
        async def async_generator():
            async for chunk in self.chat_stream_async(messages, page_path):
                yield chunk
        
        # è¿è¡Œå¼‚æ­¥ç”Ÿæˆå™¨
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            async_gen = async_generator()
            while True:
                try:
                    chunk = loop.run_until_complete(async_gen.__anext__())
                    yield chunk
                except StopAsyncIteration:
                    break
        finally:
            loop.close()
    

# å…¨å±€ Agent å®ä¾‹
_agent_instance = None

def get_agent_instance() -> WebsiteAgent:
    """è·å– Agent å•ä¾‹å®ä¾‹"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = WebsiteAgent()
    return _agent_instance

def chat_with_agent(messages: List[Dict], page_path: str = None) -> Generator[str, None, None]:
    """ä¸ Agent èŠå¤©çš„ä¾¿æ·æ¥å£"""
    print(f"ğŸ¯ chat_with_agent æ¥æ”¶åˆ°å‚æ•°:")
    print(f"  - messagesæ•°é‡: {len(messages)}")
    print(f"  - page_path: {repr(page_path)}")
    
    agent_instance = get_agent_instance()
    return agent_instance.chat_stream(messages, page_path)

