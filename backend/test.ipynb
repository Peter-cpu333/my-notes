{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad8edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import asyncio\n",
    "import requests\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "llm = ChatTongyi(api_key=os.getenv(\"DASHSCOPE_API_KEY\"), model_name=\"qwen-max\")\n",
    "\n",
    "@tool\n",
    "def read_doc_file(pageContext):\n",
    "    \"\"\"è¯»å–docsç›®å½•ä¸‹æŒ‡å®šæ–‡ä»¶çš„å†…å®¹ã€‚\"\"\"\n",
    "    base_dir = \"../docs\"\n",
    "    file_path = os.path.join(base_dir, pageContext)\n",
    "    if not os.path.isfile(file_path):\n",
    "        return f\"File {pageContext} not found in docs directory.\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_file(file_name, content):\n",
    "    \"\"\"æ ¹æ®è¦æ±‚ï¼Œå°†è¾“å‡ºçš„å†…å®¹è¿›è¡Œä¿®æ”¹åï¼Œå†™å…¥æ–‡ä»¶\"\"\"\n",
    "    file_path = os.path.join(\"../docs\", file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    return f\"æ–‡ä»¶{file_name}å·²å†™å…¥æˆåŠŸ\"\n",
    "\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "\"\"\"\n",
    "\n",
    "tools = [read_doc_file, write_file]\n",
    "agent = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"unique_thread_id\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"è®²è®²å¤§æ¨¡å‹çš„åŸç†\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f1b2a",
   "metadata": {},
   "source": [
    "## ä¿®æ”¹å¯è°ƒç”¨çš„Ai-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import asyncio\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from typing import List, Dict, Any, Generator\n",
    "\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_core.tools import tool\n",
    "from langchain.schema import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "llm = ChatTongyi(api_key=os.getenv(\"DASHSCOPE_API_KEY\"), model_name=\"qwen-max\")\n",
    "\n",
    "@tool\n",
    "def read_doc_file(pageContext):\n",
    "    \"\"\"è¯»å–docsç›®å½•ä¸‹æŒ‡å®šæ–‡ä»¶çš„å†…å®¹ã€‚\"\"\"\n",
    "    base_dir = \"../docs\"\n",
    "    file_path = os.path.join(base_dir, pageContext)\n",
    "    if not os.path.isfile(file_path):\n",
    "        return f\"File {pageContext} not found in docs directory.\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "@tool\n",
    "def write_file(file_name, content):\n",
    "    \"\"\"æ ¹æ®è¦æ±‚ï¼Œå°†è¾“å‡ºçš„å†…å®¹è¿›è¡Œä¿®æ”¹åï¼Œå†™å…¥æ–‡ä»¶\"\"\"\n",
    "    file_path = os.path.join(\"../docs\", file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    return f\"æ–‡ä»¶{file_name}å·²å†™å…¥æˆåŠŸ\"\n",
    "\n",
    "@tool\n",
    "def analyze_page_context(page_info):\n",
    "    \"\"\"åˆ†æå½“å‰é¡µé¢ä¸Šä¸‹æ–‡ä¿¡æ¯\"\"\"\n",
    "    try:\n",
    "        if isinstance(page_info, str):\n",
    "            page_data = json.loads(page_info)\n",
    "        else:\n",
    "            page_data = page_info\n",
    "            \n",
    "        page_type = page_data.get('type', 'unknown')\n",
    "        description = page_data.get('description', 'æœªçŸ¥é¡µé¢')\n",
    "        \n",
    "        analysis = {\n",
    "            'homepage': f\"ğŸ  ç”¨æˆ·å½“å‰åœ¨é¦–é¡µï¼š{description}ã€‚è¿™é‡Œæ˜¯ç½‘ç«™çš„å…¥å£ï¼ŒåŒ…å«ä¸»è¦åŠŸèƒ½ä»‹ç»ã€‚\",\n",
    "            'docs': f\"ğŸ“– ç”¨æˆ·å½“å‰åœ¨æ–‡æ¡£é¡µé¢ï¼š{description}ã€‚è¿™æ˜¯æŠ€æœ¯æ–‡æ¡£åŒºåŸŸï¼Œç”¨æˆ·å¯èƒ½éœ€è¦æ–‡æ¡£ç›¸å…³å¸®åŠ©ã€‚\",\n",
    "            'blog': f\"ğŸ“ ç”¨æˆ·å½“å‰åœ¨åšå®¢é¡µé¢ï¼š{description}ã€‚è¿™é‡Œå±•ç¤ºæ–‡ç« å’ŒæŠ€æœ¯åˆ†äº«ã€‚\",\n",
    "            'file-manager': f\"ğŸ“ ç”¨æˆ·å½“å‰åœ¨æ–‡ä»¶ç®¡ç†é¡µé¢ï¼š{description}ã€‚ç”¨æˆ·å¯èƒ½éœ€è¦æ–‡ä»¶æ“ä½œå¸®åŠ©ã€‚\",\n",
    "            'other': f\"ğŸ” ç”¨æˆ·å½“å‰åœ¨ï¼š{description}ã€‚\"\n",
    "        }\n",
    "        \n",
    "        return analysis.get(page_type, analysis['other'])\n",
    "    except Exception as e:\n",
    "        return f\"é¡µé¢ä¿¡æ¯è§£æå¤±è´¥ï¼š{str(e)}\"\n",
    "\n",
    "# åˆå§‹åŒ–å†…å­˜å’Œå·¥å…·\n",
    "memory = MemorySaver()\n",
    "\n",
    "# æ›´æ–°æç¤ºè¯ï¼ŒåŒ…å«é¡µé¢ä¸Šä¸‹æ–‡æ„ŸçŸ¥\n",
    "prompt = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘ç«™æ™ºèƒ½åŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "\n",
    "1. ğŸ“š è¯»å–å’Œåˆ†ææ–‡æ¡£å†…å®¹\n",
    "2. âœï¸ åˆ›å»ºå’Œä¿®æ”¹æ–‡ä»¶\n",
    "3. ğŸ” åˆ†æç”¨æˆ·å½“å‰é¡µé¢ä¸Šä¸‹æ–‡\n",
    "4. ğŸ’¡ æä¾›ä¸“ä¸šçš„å¼€å‘å»ºè®®\n",
    "\n",
    "è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œå½“å‰é¡µé¢ä¸Šä¸‹æ–‡ï¼Œæ™ºèƒ½é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚\n",
    "å¦‚æœç”¨æˆ·è¯¢é—®æ–‡æ¡£ç›¸å…³é—®é¢˜ï¼Œå¯ä»¥ä½¿ç”¨ read_doc_file å·¥å…·ã€‚\n",
    "å¦‚æœéœ€è¦åˆ›å»ºæˆ–ä¿®æ”¹æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ write_file å·¥å…·ã€‚\n",
    "å¦‚æœéœ€è¦äº†è§£ç”¨æˆ·å½“å‰é¡µé¢æƒ…å†µï¼Œå¯ä»¥ä½¿ç”¨ analyze_page_context å·¥å…·ã€‚\n",
    "\n",
    "å§‹ç»ˆä¿æŒå‹å¥½ã€ä¸“ä¸šçš„æ€åº¦ï¼Œæä¾›å‡†ç¡®æœ‰ç”¨çš„ä¿¡æ¯ã€‚\n",
    "\"\"\"\n",
    "\n",
    "tools = [read_doc_file, write_file, analyze_page_context]\n",
    "agent = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)\n",
    "\n",
    "# å…¨å±€é…ç½®\n",
    "config = {\"configurable\": {\"thread_id\": \"unique_thread_id\"}}\n",
    "\n",
    "class WebsiteAgent:\n",
    "    \"\"\"ç½‘ç«™æ™ºèƒ½åŠ©æ‰‹åŒ…è£…ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.agent = agent\n",
    "        self.config = config\n",
    "    \n",
    "    def chat_stream(self, messages: List[Dict], page_context: Dict = None) -> Generator[str, None, None]:\n",
    "        \"\"\"æµå¼èŠå¤©æ¥å£\"\"\"\n",
    "        try:\n",
    "            # å‡†å¤‡ç”¨æˆ·è¾“å…¥\n",
    "            user_input = messages[-1][\"content\"] if messages else \"\"\n",
    "            \n",
    "            # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯ï¼ŒåŒ…å«é¡µé¢ä¸Šä¸‹æ–‡\n",
    "            if page_context:\n",
    "                context_info = f\"\\n\\nå½“å‰é¡µé¢ä¿¡æ¯ï¼š{json.dumps(page_context, ensure_ascii=False)}\"\n",
    "                user_input_with_context = user_input + context_info\n",
    "            else:\n",
    "                user_input_with_context = user_input\n",
    "            \n",
    "            # è®°å½•è¯·æ±‚ä¿¡æ¯\n",
    "            print(f\"ğŸ¤– Agent å¤„ç†è¯·æ±‚ï¼š{user_input[:50]}...\")\n",
    "            if page_context:\n",
    "                print(f\"ğŸ“„ é¡µé¢ä¸Šä¸‹æ–‡ï¼š{page_context.get('description', 'Unknown')}\")\n",
    "            \n",
    "            # è°ƒç”¨ Agent\n",
    "            response = self.agent.invoke(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": user_input_with_context}]},\n",
    "                self.config\n",
    "            )\n",
    "            \n",
    "            # è·å–æœ€ç»ˆè¾“å‡º\n",
    "            final_output = response[\"messages\"][-1].content\n",
    "            \n",
    "            # æ¨¡æ‹Ÿæµå¼è¾“å‡º\n",
    "            chunk_size = 8  # æ¯æ¬¡è¿”å›çš„å­—ç¬¦æ•°\n",
    "            for i in range(0, len(final_output), chunk_size):\n",
    "                chunk = final_output[i:i + chunk_size]\n",
    "                yield chunk\n",
    "                time.sleep(0.03)  # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"âŒ Agent æ‰§è¡Œé”™è¯¯ï¼š{str(e)}\"\n",
    "            print(error_msg)\n",
    "            yield error_msg\n",
    "    \n",
    "    def chat_single(self, user_input: str, page_context: Dict = None) -> str:\n",
    "        \"\"\"å•æ¬¡å¯¹è¯æ¥å£\"\"\"\n",
    "        try:\n",
    "            if page_context:\n",
    "                context_info = f\"\\n\\nå½“å‰é¡µé¢ä¿¡æ¯ï¼š{json.dumps(page_context, ensure_ascii=False)}\"\n",
    "                user_input_with_context = user_input + context_info\n",
    "            else:\n",
    "                user_input_with_context = user_input\n",
    "                \n",
    "            response = self.agent.invoke(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": user_input_with_context}]},\n",
    "                self.config\n",
    "            )\n",
    "            \n",
    "            return response[\"messages\"][-1].content\n",
    "        except Exception as e:\n",
    "            return f\"âŒ Agent æ‰§è¡Œé”™è¯¯ï¼š{str(e)}\"\n",
    "\n",
    "# å…¨å±€ Agent å®ä¾‹\n",
    "_agent_instance = None\n",
    "\n",
    "def get_agent_instance() -> WebsiteAgent:\n",
    "    \"\"\"è·å– Agent å•ä¾‹å®ä¾‹\"\"\"\n",
    "    global _agent_instance\n",
    "    if _agent_instance is None:\n",
    "        _agent_instance = WebsiteAgent()\n",
    "    return _agent_instance\n",
    "\n",
    "def chat_with_agent(messages: List[Dict], page_context: Dict = None) -> Generator[str, None, None]:\n",
    "    \"\"\"ä¸ Agent èŠå¤©çš„ä¾¿æ·æ¥å£\"\"\"\n",
    "    agent_instance = get_agent_instance()\n",
    "    return agent_instance.chat_stream(messages, page_context)\n",
    "\n",
    "# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæµ‹è¯•\n",
    "if __name__ == \"__main__\":\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"è®²è®²å¤§æ¨¡å‹çš„åŸç†\"}]},\n",
    "        config=config\n",
    "    )\n",
    "    print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f195d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_area():\n",
    "    # åˆå§‹åŒ–\n",
    "    dp = [[0] * 6 for _ in range(6)]\n",
    "    area_sum = [[0] * 6 for _ in range(6)]\n",
    "    \n",
    "    # è¾¹ç•Œæ¡ä»¶\n",
    "    for i in range(6):\n",
    "        dp[i][0] = 1  # æ²¿xè½´çš„è·¯å¾„\n",
    "        dp[0][i] = 1  # æ²¿yè½´çš„è·¯å¾„\n",
    "        area_sum[i][0] = 0  # æ²¿xè½´æ— é¢ç§¯\n",
    "        area_sum[0][i] = 0  # æ²¿yè½´æ— é¢ç§¯\n",
    "    \n",
    "    # åŠ¨æ€è§„åˆ’\n",
    "    for i in range(1, 6):\n",
    "        for j in range(1, 6):\n",
    "            dp[i][j] = dp[i-1][j] + dp[i][j-1]\n",
    "            area_sum[i][j] = (area_sum[i-1][j] + \n",
    "                             area_sum[i][j-1] + \n",
    "                             i * dp[i][j-1])\n",
    "    \n",
    "    return dp[5][5], area_sum[5][5]\n",
    "\n",
    "# è®¡ç®—ç»“æœ\n",
    "paths, total_area = calculate_total_area()\n",
    "print(f\"è·¯å¾„æ€»æ•°: {paths}\")\n",
    "print(f\"æ€»é¢ç§¯: {total_area}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_client = TavilyClient(api_key=\"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\")\n",
    "response = tavily_client.extract(\"https://www.xiaohongshu.com/discovery/item/687d049a000000001202379d?app_platform=ios&app_version=8.93&share_from_user_hidden=true&xsec_source=app_share&type=normal&xsec_token=CBx7yL0b9jJTC-GE4NQwLGTJjOBPzbVGu3wPJ_IZzel8k=&author_share=1&xhsshare=CopyLink&shareRedId=ODY6NDY8PE02NzUyOTgwNjY0OTc5PEc7&apptime=1753665070&share_id=c72a11e1002040c994ef1fa913828199\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aa6341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-factory-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
